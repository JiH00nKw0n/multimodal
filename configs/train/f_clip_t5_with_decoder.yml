run:
  task: 'DatasetTrainTaskWithCustomModel'
  runner: 'RandomSamplerTrainer'
  seed: 2024

collator: 
  collator_cls: 'ImageCollator'
  config:
    max_length: 64

model:
  model_cls: 'CLIPT5ForConditionalGeneration'
  config_cls: 'CLIPT5Config'
  config:
    text_pretrained_model_name_or_path: &text_pretrained_model_name_or_path 'google-t5/t5-base'
    vision_pretrained_model_name_or_path: &vision_pretrained_model_name_or_path 'openai/clip-vit-large-patch14'
    pool_type: 'avg'
    projection_dim: 768
  lora:
    # text_model: '/mnt/elice/multimodal/multimodal/configs/lora/e5_base_v2.yml'
    # vision_model: '/mnt/elice/multimodal/multimodal/configs/lora/clip_vit_large_patch14_336.yml'

processor:
  processor_cls: "CLIPT5Processor"
  config:
      text_pretrained_model_name_or_path: 'google-t5/t5-base'
      vision_pretrained_model_name_or_path: 'openai/clip-vit-large-patch14'

dataset:
  ConceptualCaptionsDatasetBuilder:
    split: 'train'

trainer:
  output_dir: '/mnt/elice/multimodal/output/frozen-clip-t5'
  run_name: 'frozen-clip-t5'
  learning_rate: &learning_rate 1.0e-4
  lr_scheduler_type: 'cosine'
  warmup_steps: &warmup_steps 100
  weight_decay: &weight_decay 1.0e-1
  save_steps: 1000
  logging_steps : 1
  eval_strategy: 'no' # 'steps', 'epochs', 'no'
  # dataloader_num_workers: 16

  num_train_epochs: 5
  per_device_train_batch_size : &per_device_batch_size 512
  gradient_accumulation_steps: &gradient_accumulation 1
  # For memory efficiency.
  gradient_checkpointing : True
  # NOTE : need to use this option to cope with DDP
  gradient_checkpointing_kwargs:
    use_reentrant: False
  ddp_find_unused_parameters: True

  group_by_length : False # Whether to order the sample by token length.
  use_cpu : False
  remove_unused_columns : False